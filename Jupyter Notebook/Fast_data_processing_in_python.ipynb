{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"Purple\">Faster data processing in Python</font>\n",
    "\n",
    "Working with data in Python requires making a number of choices.\n",
    "\n",
    "- What format should I save data in? CSV? JSON? Pickle?\n",
    "- What library should I read data with?\n",
    "- How should I parse dates?\n",
    "- How to make my program restartable?\n",
    "- How do I run a function in parallel?\n",
    "\n",
    "Let's discuss how to make these choices with the aim of running code faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualising the elections\n",
    "\n",
    "This is the story of the back-end optimisations we were making during the CNN-IBN - Microsoft election visualisations in May 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"853\"\n",
       "            height=\"480\"\n",
       "            src=\"https://www.youtube.com/embed/bMicxDcxefs?start=30\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f8ee0440be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo('bMicxDcxefs', width=853, height=480, start=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's start with the raw data\n",
    "\n",
    "The first step in data processing is to load the data. We'd scraped the results of [assembly elections](https://gramener.com/election/cartogram?ST_NAME=Tamil%20Nadu) to see which consitituency had the largest number of candidates, votes, etc. This is what the raw data file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST_NAME,YEAR,AC_NO,#,AC_NAME,AC_TYPE,NAME,SEX,AGE,CATEGORY,PARTY,VOTES\n",
      "Andhra Pradesh,1955,1,1,ICHCHAPURAM,GEN,UPPADA RANGABABU,M,,,KLP,14565\n",
      "Andhra Pradesh,1955,1,2,ICHCHAPURAM,GEN,HARIHARA PATNAIK,M,,,IND,7408\n",
      "Andhra Pradesh,1955,1,3,ICHCHAPURAM,GEN,PUDI LOKANADHAM,M,,,IND,6508\n",
      "Andhra Pradesh,1955,1,4,ICHCHAPURAM,GEN,KALLA BALARAMA SWAMY,M,,,IND,\n"
     ]
    }
   ],
   "source": [
    "assembly_results = 'D:/site/gramener.com/viz/election/assembly.csv'\n",
    "print open(assembly_results).read(350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Who got the most votes?\n",
    "\n",
    "An \"entrance exam\" question we have at Gramener is to ask candidates to load a CSV file and sort it in descending order of a given column. For example, when told \"Write a program to find out who got the most votes in Bangalore South, ever\", here's the most common response we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M. KRISHNAPPA', 102207],\n",
       " ['R. PRABHAKARA REDDY', 72045],\n",
       " ['M KRISHNAPPA', 71114],\n",
       " ['DR.TEJASWINI GOWDA', 63849],\n",
       " ['SADANANDA M', 36979],\n",
       " ['C MANJUNATH', 33529],\n",
       " ['H P RAJAGOPALA REDDY', 17726],\n",
       " ['D. MUNICHINNAPPA', 17441],\n",
       " ['A. V. NARASIMHA REDDY', 13702],\n",
       " ['R. RANGAPPA REDDY', 13452],\n",
       " ['B. BASAVALINGAPPA (SC)', 12365],\n",
       " ['B. BASAVALINGAPPA', 11540],\n",
       " ['B. T. KEMPA RAJ (SC)', 5449],\n",
       " ['C. BASAVIAH', 5333],\n",
       " ['JAGADISH REDDY', 3936],\n",
       " ['SHIVARUDRAPPA', 2610],\n",
       " ['K. CHIKKANNA', 2561],\n",
       " ['KRISHNAMA RAJU', 2509],\n",
       " ['R MANJUNATH', 2300],\n",
       " ['P. S. CHINNAPPA', 2229],\n",
       " ['MURALI MOHAN', 1975],\n",
       " ['A SOMASHEKAR', 1755],\n",
       " ['M. NARAYANAPPA', 1494],\n",
       " ['N S RAVICHANDRA', 1494],\n",
       " ['VASANTH', 1363],\n",
       " ['G.A. GREGORY', 1347],\n",
       " ['E KRISHNAPPA', 1040],\n",
       " ['M KRISHNAPPA', 990],\n",
       " ['LOKESH M R', 771],\n",
       " ['A. CHOWARAPPA', 691],\n",
       " ['T.N KAMAL', 639],\n",
       " ['N.S. RAVICHANDRA', 509],\n",
       " ['JAYARAMA Y', 410],\n",
       " ['K GURURAJ', 407],\n",
       " ['ASHISH KAPUR', 394],\n",
       " ['SUNDARAPPA', 335]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []                                       # Store results\n",
    "row = 0                                         # Row number in data file\n",
    "for line in open(assembly_results):             # Loop through each line\n",
    "    row += 1                                    # Increment row counter\n",
    "    if row > 1:                                 # Ignore the first line\n",
    "        csv_row = line.split(',')               #   Split by commas\n",
    "        if csv_row[4] == 'BANGALORE SOUTH':     #   AC_NAME is in 5th column\n",
    "            name = csv_row[6]                   #   name is the 7th column\n",
    "            votes = int(csv_row[11].strip())    #   votes (12th) may have trailing \\n\n",
    "            data.append([name, votes])          # 6 = NAME, 11 = VOTES\n",
    "\n",
    "import operator\n",
    "sorted(data, key=operator.itemgetter(1), reverse=True)    # Sort in descending order of votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before you optimise, *time it*\n",
    "\n",
    "But let's see how we can make the program faster. The first step towards that is to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 387 ms per loop\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def most_votes(ac_name='BANGALORE SOUTH'):\n",
    "    data = []\n",
    "    row = 0\n",
    "    for line in open(assembly_results):\n",
    "        row += 1\n",
    "        if row > 1:\n",
    "            csv_row = line.split(',')\n",
    "            if csv_row[4] == ac_name:\n",
    "                name = csv_row[6]\n",
    "                votes = int(csv_row[11].strip())\n",
    "                data.append([name, votes])\n",
    "\n",
    "    return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "%timeit most_votes('BANGALORE_SOUTH')               # %timeit is IPython's timing magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is it fast enough?\n",
    "\n",
    "That's a fairly slow function. But what's taking up so much time? Can we narrow down to the line that takes up the most time?\n",
    "\n",
    "At this time, I'd like to quote Calvin.\n",
    "\n",
    "![Do I even care?](http://picayune.uclick.com/comics/ch/1993/ch930108.gif)\n",
    "\n",
    "Premature optimisation is the root of all evil. Make sure you get the functionality right first. Then ask the question, \"Do you even care that it's slow?\" Only if the answer is yes do we proceed.\n",
    "\n",
    "At this point, **find and optimise the slowest part. *Only* the slowest part.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Find the slowest part\n",
    "\n",
    "For this, we'll use the `line_profiler` module.\n",
    "\n",
    "    pip install line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You'll need some more setup to make this an extension. See http://pynash.org/2013/03/06/timing-and-profiling.html for details.\n",
    "\n",
    "Once set up, you can load it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "%lprun -f most_votes most_votes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This displays it in a separate window in IPython Notebook. So let's create a new function that displays it as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import line_profiler\n",
    "\n",
    "def lprun(func, *args, **kwargs):\n",
    "    profile = line_profiler.LineProfiler(func)\n",
    "    profile.runcall(func, *args, **kwargs)\n",
    "    profile.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 4.66512e-07 s\n",
      "\n",
      "Total time: 1.98855 s\n",
      "File: <ipython-input-5-299e00e75fb3>\n",
      "Function: most_votes at line 3\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     3                                           def most_votes(ac_name='BANGALORE SOUTH'):\n",
      "     4         1            6      6.0      0.0      data = []\n",
      "     5         1            2      2.0      0.0      row = 0\n",
      "     6    398704       866654      2.2     20.3      for line in open(assembly_results):\n",
      "     7    398703       694258      1.7     16.3          row += 1\n",
      "     8    398703       623570      1.6     14.6          if row > 1:\n",
      "     9    398702      1317660      3.3     30.9              csv_row = line.split(',')\n",
      "    10    398702       760068      1.9     17.8              if csv_row[4] == ac_name:\n",
      "    11        36           54      1.5      0.0                  name = csv_row[6]\n",
      "    12        36          161      4.5      0.0                  votes = int(csv_row[11].strip())\n",
      "    13        36           94      2.6      0.0                  data.append([name, votes])\n",
      "    14                                           \n",
      "    15         1           56     56.0      0.0      return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprun(most_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pick your battle\n",
    "\n",
    "Now that we know what's taking time, there are two approaches to pick what to optimise:\n",
    "\n",
    "1. Eliminate what's obviously redundant\n",
    "2. Optimise what takes the most time\n",
    "    1. Reduce the number of Hits\n",
    "    2. Reduce the time per hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eliminate the obviously redundant\n",
    "\n",
    "Let's look at whether anything is obviously redundant. Consider the line:\n",
    "\n",
    "    if row > 1\n",
    "\n",
    "That's being checked 398,703 times. But in reality, it needs to be checked only once. We just want to ignore the first row. So let's refactor the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 416 ms per loop\n",
      "1 loops, best of 3: 408 ms per loop\n",
      "0.9% faster\n"
     ]
    }
   ],
   "source": [
    "def most_votes_skip_first(ac_name='BANGALORE SOUTH'):\n",
    "    data = []\n",
    "    handle = open(assembly_results)\n",
    "    handle.next()  # Skip the header\n",
    "    for line in handle:\n",
    "        csv_row = line.split(',')\n",
    "        if csv_row[4] == ac_name:\n",
    "            name = csv_row[6]\n",
    "            votes = int(csv_row[11].strip())\n",
    "            data.append([name, votes])\n",
    "\n",
    "    return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "time1 = %timeit -o most_votes()\n",
    "time2 = %timeit -o most_votes_skip_first()\n",
    "ms = lambda time: 1000. * sum(time.all_runs) / len(time.all_runs) / time.loops\n",
    "print '{:.1%} faster'.format(ms(time1) / ms(time2) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimise what takes most time\n",
    "\n",
    "Now, let's see what takes the most time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 4.66512e-07 s\n",
      "\n",
      "Total time: 1.33709 s\n",
      "File: <ipython-input-9-82bed0413cd3>\n",
      "Function: most_votes_skip_first at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def most_votes_skip_first(ac_name='BANGALORE SOUTH'):\n",
      "     2         1            7      7.0      0.0      data = []\n",
      "     3         1          310    310.0      0.0      handle = open(assembly_results)\n",
      "     4         1          147    147.0      0.0      handle.next()  # Skip the header\n",
      "     5    398703       860141      2.2     30.0      for line in handle:\n",
      "     6    398702      1302605      3.3     45.4          csv_row = line.split(',')\n",
      "     7    398702       702552      1.8     24.5          if csv_row[4] == ac_name:\n",
      "     8        36           56      1.6      0.0              name = csv_row[6]\n",
      "     9        36          172      4.8      0.0              votes = int(csv_row[11].strip())\n",
      "    10        36          101      2.8      0.0              data.append([name, votes])\n",
      "    11                                           \n",
      "    12         1           57     57.0      0.0      return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprun(most_votes_skip_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduce the number of hits\n",
    "\n",
    "The bulk of the time is going into splitting the ','. This is called 398,702 times, once for each row.\n",
    "\n",
    "However, we are only interested in those rows where the constituency name matches. So let's check for the name first, without bothering to split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 232 ms per loop\n",
      "61.5% faster\n"
     ]
    }
   ],
   "source": [
    "def most_votes_check_first(ac_name='BANGALORE SOUTH'):\n",
    "    data = []\n",
    "    handle = open(assembly_results)\n",
    "    handle.next()\n",
    "    for line in handle:\n",
    "        # Check for a match first, before split\n",
    "        if line.find(ac_name) >= 0:\n",
    "            csv_row = line.split(',')\n",
    "            name = csv_row[6]\n",
    "            votes = int(csv_row[11].strip())\n",
    "            data.append([name, votes])\n",
    "\n",
    "    return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "time3 = %timeit -o most_votes_check_first()\n",
    "print '{:.1%} faster'.format(ms(time2) / ms(time3) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So now, the bulk of the time is going into just checking if the `ac_name` is in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 4.66512e-07 s\n",
      "\n",
      "Total time: 0.837494 s\n",
      "File: <ipython-input-11-6ceaa1572cb1>\n",
      "Function: most_votes_check_first at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def most_votes_check_first(ac_name='BANGALORE SOUTH'):\n",
      "     2         1            6      6.0      0.0      data = []\n",
      "     3         1          312    312.0      0.0      handle = open(assembly_results)\n",
      "     4         1          157    157.0      0.0      handle.next()\n",
      "     5    398703       842836      2.1     46.9      for line in handle:\n",
      "     6                                                   # Check for a match first, before split\n",
      "     7    398702       951415      2.4     53.0          if line.find(ac_name) >= 0:\n",
      "     8        36          132      3.7      0.0              csv_row = line.split(',')\n",
      "     9        36           57      1.6      0.0              name = csv_row[6]\n",
      "    10        36          152      4.2      0.0              votes = int(csv_row[11].strip())\n",
      "    11        36           98      2.7      0.0              data.append([name, votes])\n",
      "    12                                           \n",
      "    13         1           60     60.0      0.0      return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprun(most_votes_check_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduce the time per hit\n",
    "\n",
    "So how exactly can we make something as simple as `line.find(ac_name) >= 0` faster?\n",
    "\n",
    "Let's loop at the op code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2           0 LOAD_FAST                0 (line)\n",
      "              3 LOAD_ATTR                0 (find)\n",
      "              6 LOAD_FAST                1 (ac_name)\n",
      "              9 CALL_FUNCTION            1\n",
      "             12 LOAD_CONST               1 (0)\n",
      "             15 COMPARE_OP               5 (>=)\n",
      "             18 RETURN_VALUE        \n"
     ]
    }
   ],
   "source": [
    "def check(line, ac_name):\n",
    "    return line.find(ac_name) >= 0\n",
    "\n",
    "import dis\n",
    "dis.disassemble(check.func_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "There are a number of steps involved here:\n",
    "\n",
    "1. Load `line`\n",
    "2. Load `find`\n",
    "3. Load `ac_name`\n",
    "4. Then call the `line.find` function with `ac_name` as a parameter\n",
    "5. Load the constant `0`\n",
    "6. Compare the result with that constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's generally recognised that functions in Python are slow. Let's replace this with an operator and see how well that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2           0 LOAD_FAST                1 (ac_name)\n",
      "              3 LOAD_FAST                0 (line)\n",
      "              6 COMPARE_OP               6 (in)\n",
      "              9 RETURN_VALUE        \n"
     ]
    }
   ],
   "source": [
    "def check(line, ac_name):\n",
    "    return ac_name in line\n",
    "\n",
    "dis.disassemble(check.func_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This appears to be doing a *lot less* than before. Let's try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 148 ms per loop\n",
      "76.7% faster\n"
     ]
    }
   ],
   "source": [
    "def most_votes_using_in(ac_name='BANGALORE SOUTH'):\n",
    "    data = []\n",
    "    handle = open(assembly_results)\n",
    "    handle.next()\n",
    "    for line in handle:\n",
    "        # Use `in` instead of `.find()`\n",
    "        if ac_name in line:\n",
    "            csv_row = line.split(',')\n",
    "            name = csv_row[6]\n",
    "            votes = int(csv_row[11].strip())\n",
    "            data.append([name, votes])\n",
    "\n",
    "    return sorted(data, key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "time4 = %timeit -o most_votes_using_in()\n",
    "print '{:.1%} faster'.format(ms(time3) / ms(time4) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, overall, here's our overall improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    445 ms: original version\n",
      "   0.9% faster: remove redundant if row > 0\n",
      "  61.5% faster: reduce # times .split() is called\n",
      "  76.7% faster: use operator instead of function\n",
      " 188.1% faster: total\n"
     ]
    }
   ],
   "source": [
    "print '{: 7,.0f} ms: original version'.format(ms(time1))\n",
    "print '{: 7,.1%} faster: remove redundant if row > 0'.format(ms(time1) / ms(time2) - 1)\n",
    "print '{: 7,.1%} faster: reduce # times .split() is called'.format(ms(time2) / ms(time3) - 1)\n",
    "print '{: 7,.1%} faster: use operator instead of function'.format(ms(time3) / ms(time4) - 1)\n",
    "print '{: 7,.1%} faster: total'.format(ms(time1) / ms(time4) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reject dogmas\n",
    "\n",
    "By now, you'd wonder, \"Why not use NumPy? Pandas? That's got to be faster.\" And it often is.\n",
    "\n",
    "So let's try it. We'll use Pandas to achieve the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.03 s per loop\n",
      "-87.1% faster\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def most_votes_pandas(ac_name='BANGALORE SOUTH'):\n",
    "    data = pd.read_csv(assembly_results, low_memory=False)\n",
    "    return data[data.AC_NAME.str.contains(ac_name)].sort('VOTES', ascending=False)\n",
    "\n",
    "time5 = %timeit -o most_votes_pandas()\n",
    "print '{:.1%} faster'.format(ms(time4) / ms(time5) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Shocking as it is, using Pandas is slower in this particular scenario.\n",
    "\n",
    "In fact, we can evaluate how fast long it takes for various storage methods. Below, we create a set of dummy data files in a variety of formats (CSV, JSON, pickle, HDF5) and load them to see how long each takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Which is the fastest data format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%run sample.data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.403s: csv.DictReader\n",
      "5.663s: pickle.load\n",
      "7.016s: json.load (array of dict)\n",
      "2.226s: json.load (array of arrays)\n",
      "1.217s: csv.reader\n",
      "0.788s: pandas.read_csv\n",
      "3.293s: pandas.read_pickle\n",
      "0.833s: HDF5 table\n",
      "0.292s: HDF5 stored\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "print '{:,.3f}s: csv.DictReader'.format(timeit(\"list(csv.DictReader(open('sample.data.csv')))\", setup=\"import csv\", number=1))\n",
    "print '{:,.3f}s: pickle.load'.format(timeit(\"pickle.load(open('sample.data.pickle', 'rb'))\", setup=\"import cPickle as pickle\", number=1))\n",
    "print '{:,.3f}s: json.load (array of dict)'.format(timeit(\"json.load(open('sample.data.json'))\", setup=\"import json\", number=1))\n",
    "print '{:,.3f}s: json.load (array of arrays)'.format(timeit(\"json.load(open('sample.data-array.json'))\", setup=\"import json\", number=1))\n",
    "print '{:,.3f}s: csv.reader'.format(timeit(\"list(csv.reader(open('sample.data.csv')))\", setup=\"import csv\", number=1))\n",
    "print '{:,.3f}s: pandas.read_csv'.format(timeit(\"pd.read_csv('sample.data.csv')\", setup=\"import pandas as pd\", number=1))\n",
    "print '{:,.3f}s: pandas.read_pickle'.format(timeit(\"pd.read_pickle('sample.data.pandas')\", setup=\"import pandas as pd\", number=1))\n",
    "print '{:,.3f}s: HDF5 table'.format(timeit(\"pd.read_hdf('sample.data.h5', 'table')\", setup=\"import pandas as pd\", number=1))\n",
    "print '{:,.3f}s: HDF5 stored'.format(timeit(\"pd.read_hdf('sample.data.h5', 'stored')\", setup=\"import pandas as pd\", number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Only the HDF5 format comes close to the speed at which our custom algorithm performed, and even then, does not quite meet it.\n",
    "\n",
    "So remember: **the best optimiser is your head**. But all else being equal, prefer HDF5 as a format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next topic: optimising scraping\n",
    "\n",
    "In order to get the assembly results, we had to scrape the results from the [ECI results](http://eci.nic.in/eci_main1/ElectionStatistics.aspx) page.\n",
    "\n",
    "Here, the problem is not that the computations are slow.\n",
    "\n",
    "It's not even that the network is slow.\n",
    "\n",
    "It's that the *network is unreliable* at this scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Make your programs restartable\n",
    "\n",
    "If you're running a large computation, two things become critical:\n",
    "\n",
    "1. Break it into pieces and process them separately (effectively, map-reduce-ability)\n",
    "2. Cache the results so that re-computations are avoided\n",
    "\n",
    "The latter, caching, is the key to the \"restartability\" of a program -- where it can pick up an run fom where it stopped the last time. Here's a fairly typical scraping sequence:\n",
    "\n",
    "    for url in list_of_urls:\n",
    "        tree = parse(url)\n",
    "        # ... do more with the tree\n",
    "\n",
    "The slowest step in this is not the computation, but fetching the URL. Can we cache it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cache slow operations transparently\n",
    "\n",
    "One way is to define a method that loads the URL only if it has not already been created. Here's one simple possibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 9.24 s per loop\n",
      "1 loops, best of 1: 174 µs per loop\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib import urlretrieve\n",
    "\n",
    "def get(url):\n",
    "    '''Like open(url), but cached'''\n",
    "    filename = 'sample.file.name'         # We need a unique filename per URL\n",
    "    if not os.path.exists(filename):\n",
    "        urlretrieve(url, filename)\n",
    "    return open(filename)\n",
    "\n",
    "!rm -f sample.file.name\n",
    "eci_url = 'http://eci.nic.in/eci_main1/ElectionStatistics.aspx'\n",
    "%timeit -n1 -r1 get(eci_url)\n",
    "%timeit -n1 -r1 get(eci_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file gets saved the first time. The second time, it's loaded from the disk, which is *thousands of times* faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cache each URL as a unique key\n",
    "\n",
    "But in our last example, the filename was not unique. We need a way of getting a unique filename for each URL. There are several options for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**1. Use the URL as the filename.** But not all URL characters are valid for files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**2. Remove special characters from the URL.** But some special characters have meaning. `?x=1` is different from `/x/1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**3. Use a hashing function**. Which begs the question, which one? And since this is a session on speed, let's time them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hashing efficiently\n",
    "\n",
    "My first impulse is to use the `hashlib` built-in library. Here's how the various algorithms perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.572s: md5\n",
      "1.669s: sha1\n",
      "1.840s: sha224\n",
      "1.800s: sha256\n",
      "2.760s: sha384\n",
      "3.321s: sha512\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "for algo in hashlib.algorithms:\n",
    "    duration = timeit('hashlib.%s(\"%s\").hexdigest()' % (algo, eci_url), setup='import hashlib')\n",
    "    print '{:,.3f}s: {:s}'.format(duration, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results for 1 million operations, so the time taken per hash is a few microseconds. So we really *should not* be optimising this, and should just randomly pick an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The built-in `hash` function\n",
    "\n",
    "However, let me just remind you of the built-in `hash()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159908681"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(eci_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It converts any hashable object into a signed long. We can just add `2 ** 32` to convert this into an unsigned long, which is a perfectly valid filename in almost every OS. This is what Python internally uses for dictionary keys. So it's likely to be fast. In fact, let's measure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.196s: hash\n"
     ]
    }
   ],
   "source": [
    "duration = timeit('hash(\"%s\") + 2**32')\n",
    "print '{:,.3f}s: hash'.format(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember -- the hash is not guaranteed to be identical across different runs. It is quite likely to change between Python versions, so if you're storing the cache on different machines, or running multiple Python versions, you're better off with MD5.\n",
    "\n",
    "(This, incidentally, is yet another case of premature optimisation!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next topic: Parsing dates\n",
    "\n",
    "We were exploring views to show [every assembly election in India](https://gramener.com/election/assembly). Since we have the dates of every election, and the people that were Chief Ministers after each election, we decided to put these together as a set of visualisations.\n",
    "\n",
    "The slowest step when processing this data was parsing the dates. For example, let's create a dummy data file that saves dates. To make it realistic, we'll use multiple formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-04-11\n",
      "13 03 2015\n",
      "10 05 2015\n",
      "27 03 2015\n",
      "25-Apr-2015\n",
      "13 03 2015\n",
      "25-Mar-2015\n",
      "2015-03-16\n",
      "2015-05-20\n",
      "2015-06-05\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "formats = ['%d-%b-%Y', '%d %m %Y', '%b %d %Y', '%Y-%m-%d']\n",
    "today = datetime.date.today()\n",
    "with open('sample.dates.csv', 'w') as out:\n",
    "    for x in range(100000):\n",
    "        date = today - datetime.timedelta(random.randint(0, 100))\n",
    "        out.write(date.strftime(random.choice(formats)) + '\\n')\n",
    "\n",
    "!head sample.dates.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since the dates are in multiple formats, we need a good library to parse it. [dateutil](https://labix.org/python-dateutil) is the most popular flexible date processor. Let's see how long that takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 8.17 s per loop\n"
     ]
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "# Read the data first into a list\n",
    "lines = [line.strip() for line in open('sample.dates.csv')]\n",
    "\n",
    "# Convert it into dates\n",
    "def convert(lines):\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        date = parse(line, dayfirst=True)\n",
    "        result.append(date)\n",
    "\n",
    "%timeit convert(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Where do *you* think the problem is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The entire problem is in the date parsing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 4.66512e-07 s\n",
      "\n",
      "Total time: 27.5383 s\n",
      "File: <ipython-input-25-10962859084c>\n",
      "Function: convert at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def convert(lines):\n",
      "     8         1            6      6.0      0.0      result = []\n",
      "     9    100001        97698      1.0      0.2      for line in lines:\n",
      "    10    100000     58725467    587.3     99.5          date = parse(line, dayfirst=True)\n",
      "    11    100000       207084      2.1      0.4          result.append(date)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lprun(convert, lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluate alternatives\n",
    "\n",
    "Let's see whether we have options to make date parsing faster. Suppose we take a single date, and see how long that takes to parse.\n",
    "\n",
    "Let's start with Pandas' `to_datetime` method (which internally uses `dateutil.parser.parse`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 7.57 s per loop\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['01-31-2012']*100000)\n",
    "\n",
    "%timeit pd.to_datetime(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "That wasn't fast. Let's see if the native `dateutil.parser.parse` is any faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 6.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit [parse(v) for v in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But wait... in this case, we *already know the string format*. Can't we just use `datetime.strptime()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.64 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit [datetime.datetime.strptime(v, '%m-%d-%Y') for v in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Looking much better. But what if the overhead of `datetime.strptime()` is high. Let's try parsing it raw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 220 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit [datetime.datetime(int(v[6:10]), int(v[0:2]), int(v[3:5])) for v in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So we've gotten it to be over *20 times faster*, but this is at the expense of flexibility. We can only parse one date format, and that too only if it has integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cache anything that's slow\n",
    "\n",
    "But let's take a different approach. So far, we were trying to make the function faster. But what if we tried to call it fewer times? Often, the number of dates to be parsed are few. There's no reason not to cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 9.75 ms per loop\n"
     ]
    }
   ],
   "source": [
    "def lookup(s):\n",
    "    # Parse only the unique dates\n",
    "    dates = {date: parse(date, dayfirst=True) for date in set(s)}\n",
    "    # Look up the parsed dates\n",
    "    return [dates[v] for v in s]\n",
    "\n",
    "%timeit lookup(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Now, this is a substantial improvement, and comes without any loss of flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next topic: Loops and functions\n",
    "\n",
    "You'll notice that I've switched over to using list comprehensions in favour of loops. That's because loops and functions both have an overhead in Python -- so where possible, it's best to avoid them. Let me show you how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 25.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "data = [random.randint(0, 100) for x in range(100000)]\n",
    "\n",
    "def square(value):\n",
    "    return value * value\n",
    "\n",
    "def square_all(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        squared = square(value)\n",
    "        result.append(squared)\n",
    "    return result\n",
    "\n",
    "time1 = %timeit -o square_all(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inline functions are faster\n",
    "\n",
    "Now, let's take the same function, but avoid the overhead of calling a function. We'll inline the `square` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 15.3 ms per loop\n",
      "62.1% faster\n"
     ]
    }
   ],
   "source": [
    "def square_all_2(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        squared = value * value\n",
    "        result.append(squared)\n",
    "    return result\n",
    "\n",
    "time2 = %timeit -o square_all_2(data)\n",
    "print '{:.1%} faster'.format(ms(time1) / ms(time2) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We're storing the squared value in a temporary variable that's not being re-used. Let's see if removing that makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 13.8 ms per loop\n",
      "9.5% faster\n"
     ]
    }
   ],
   "source": [
    "def square_all_3(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        result.append(value * value)\n",
    "    return result\n",
    "\n",
    "time3 = %timeit -o square_all_3(data)\n",
    "print '{:.1%} faster'.format(ms(time2) / ms(time3) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# List comprehensions are faster than loops\n",
    "\n",
    "Now, let's remove the for loop and replace it with a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.79 ms per loop\n",
      "105.9% faster\n"
     ]
    }
   ],
   "source": [
    "def square_all_4(data):\n",
    "    return [value * value for value in data]\n",
    "\n",
    "time4 = %timeit -o square_all_4(data)\n",
    "print '{:.1%} faster'.format(ms(time3) / ms(time4) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In other words, where possible\n",
    "\n",
    "1. Use list comprehensions instead of loops\n",
    "2. Inline the function calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Think in vectors\n",
    "\n",
    "Let's try another approach to squaring these random numbers. Let's use `pandas`, which converts these into an array with a fixed datatype, and executes loops in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 424 µs per loop\n",
      "1523.1% faster\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series(data)\n",
    "\n",
    "time5 = %timeit -o data * data\n",
    "print '{:.1%} faster'.format(ms(time4) / ms(time5) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "That might be termed *blazing fast*. Most vector computations have the dual advantages of:\n",
    "\n",
    "- static typing (so no type checking or conversions are required)\n",
    "- C loops (so no overhead of handling exceptions, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here's another example where you could have a much faster result with vector computations. If you want to scale a dataset into the range [0 - 1], this piece of code is quite fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.09 ms per loop\n"
     ]
    }
   ],
   "source": [
    "lo, hi = data.min(), data.max()\n",
    "%timeit (data - lo) / (hi - lo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Having read [this post](http://blog.clifreeder.com/blog/2013/04/21/ruby-is-too-slow-for-programming-competitions/) on Ruby being slow, I thought I'd check the same with Python. I got it running fairly fast, but there was one piece that was taking a fair bit of time: *counting numbers in a range*. Here's the slow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 210 ms per loop\n"
     ]
    }
   ],
   "source": [
    "values = pd.np.random.rand(1000000)\n",
    "def count(values, a, b):\n",
    "    count = 0\n",
    "    for x in values:\n",
    "        if a <= x <= b:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "time1 = %timeit -o count(values, .25, .75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vector calculations are *much* faster than looping\n",
    "\n",
    "Let's apply vector computations to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.05 ms per loop\n",
      "6676.4% faster\n"
     ]
    }
   ],
   "source": [
    "time2 = %timeit -o ((.25 <= values) & (values <= .75)).sum()\n",
    "print '{:.1%} faster'.format(ms(time1) / ms(time2) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But you can make it even faster\n",
    "\n",
    "That was pretty fast, but we can go even faster when we realise that the search would be much quicker if the values are sorted. Rather than check each value, we can apply binary search on it.\n",
    "\n",
    "Fortunately, `numpy.searchsorted` provides a built-in and fast binary search. When you apply that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.04 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 3.46 µs per loop\n",
      "90794.1% faster\n"
     ]
    }
   ],
   "source": [
    "values.sort()\n",
    "time3 = %timeit -o pd.np.searchsorted(values, .75) - pd.np.searchsorted(values, .25)\n",
    "print '{:.1%} faster'.format(ms(time2) / ms(time3) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So remember, again: **the best optimiser is your head**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next topic: writing C in Python &mdash; Cython\n",
    "\n",
    "[Cython](http://docs.cython.org/) is a project that lets you write C extensions to Python using Python -- that is, you don't need to know much C. There are many ways to [install it](http://docs.cython.org/src/quickstart/install.html) but a distribution like [Anaconda](http://docs.continuum.io/anaconda/) makes it much easier to install.\n",
    "\n",
    "Once installed, you can use it in IPython like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "From this point, any cell beginning with `%%cython` will be interpreted using Cython, not Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cython code is just like Python\n",
    "\n",
    "Here's the code to add up numbers up to n, written in Cython and Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "def total_cython(n):\n",
    "    '''Calculate the sum of all numbers up to n'''\n",
    "    cdef int a = 0        # Declare the type of a as integer\n",
    "    cdef int i            # Declare the type of i as integer\n",
    "    for i in xrange(n):   # Now loop through all the numbers\n",
    "        a += i            # ... and add them\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def total_python(n):\n",
    "    a = 0\n",
    "    for i in xrange(n):\n",
    "        a += i\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cython can be much faster than Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.1 ms per loop\n",
      "10000 loops, best of 3: 62.1 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit total_python(100000)\n",
    "%timeit total_cython(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In this case, Cython is almost 100 times faster than Python. A fair bit of Python's overhead lies in the flexible type system and loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But Cython is not always blazing fast\n",
    "\n",
    "Let's count the number of values between `a` and `b` like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def count_cython(values, a, b):\n",
    "    cdef int count = 0\n",
    "    cdef float val\n",
    "    for val in values:\n",
    "        if a <= val <= b:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 214 ms per loop\n",
      "10 loops, best of 3: 84.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit count(values, .25, .75)\n",
    "%timeit count_cython(values, .25, .75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The speed difference between Python and Cython is still considerable, but much smaller than the almost 100x improvement we got earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numba is simpler than Cython\n",
    "\n",
    "[Numba](http://numba.pydata.org/) dynamically compiles Python code and makes it faster. Its speed rivals Cython's, and it's a lot easier to use. For example, to compile the `total` function, use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from numba.decorators import jit\n",
    "\n",
    "@jit\n",
    "def total_numba(n):\n",
    "    a = 0\n",
    "    for i in range(n):\n",
    "        a += i\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.03 ms per loop\n",
      "10000 loops, best of 3: 62.6 µs per loop\n",
      "The slowest run took 277890.41 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 265 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit total_python(100000)\n",
    "%timeit total_cython(100000)\n",
    "%timeit total_numba(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the units. Milliseconds, microseconds, *nano*seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numba is often faster than Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 205 ms per loop\n",
      "10 loops, best of 3: 83.9 ms per loop\n",
      "The slowest run took 100.25 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 764 µs per loop\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def count_numba(values, a, b):\n",
    "    count = 0\n",
    "    for i in range(len(values)):\n",
    "        if a <= values[i] and values[i] <= b:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "%timeit count(values, .25, .75)\n",
    "%timeit count_cython(values, .25, .75)\n",
    "%timeit count_numba(values, .25, .75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "1. If it's fast enough, don't optimise it.\n",
    "2. Find the slowest step first.\n",
    "3. Reduce the number of hits. Perform each operation as rarely as possible.\n",
    "    - Cache the result if speed is more important than memory\n",
    "    - Move slower operations inside `if` conditions\n",
    "4. Make the slowest operation faster\n",
    "    - Python functions have an overhead. Inline if possible\n",
    "    - List comprehensions are faster than `for` or `if`\n",
    "    - Use Numba or Cython if static typing, etc can help\n",
    "5. Change the algorithm. This has the second-biggest impact on speed\n",
    "6. The largest impact comes from eliminating code.\n",
    "\n",
    "> Functionality is an asset. Code is a liability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix\n",
    "\n",
    "I'm sometimes asked what I use for parallel processing. My answer is [xargs](http://en.wikipedia.org/wiki/Xargs). It is devilishly powerful.\n",
    "\n",
    "**Why `xargs`?** Because\n",
    "\n",
    "1. It's ridiculously simple to use.\n",
    "2. It lets me distribute load across CPUs / cores in a machine, *as well as* across machines\n",
    "\n",
    "**Why not `threading`?** Threads are lightweight, but when processing data, you're not processing lightweight stuff. Threading helps share data. But you *don't want to share data* -- you want to process each chunk of data exactly once, and get rid of it. Threads do not have a big benefit over processes in the data world.\n",
    "\n",
    "**Why not `multiprocessing`?** The key benefit here (when compared to xargs) is that I can pass Python objects. But the disadvantage is that I cannot run the same code across multiple servers.\n",
    "\n",
    "This is not to say that these modules are not useful. Just that it's not too relevant when processing large-scale data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
